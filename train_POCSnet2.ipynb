{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from model_structures import *\n",
    "from data_loader import *\n",
    "from loss_func import *\n",
    "from QSM_func import *\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import time\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}\n",
    "\n",
    "opt['train_path'] = '/home/sylar/data/Simu/dp_inv_simu_train/simu_new_dipole/simu_111'\n",
    "opt['train_img1_path'] = ['/phs/phs']\n",
    "opt['train_img2_path'] = ['/phs/phs']\n",
    "opt['train_label_path'] = ['/qsm/qsm']\n",
    "\n",
    "opt['reso'] = (1,1,1)\n",
    "opt['patch_size'] = (64,64,64)\n",
    "\n",
    "opt['lbd2'] = 0.1\n",
    "opt['iter'] = 5\n",
    "opt['batch_size']= 15\n",
    "opt['channels'] = 1\n",
    "opt['img_shape'] = opt['patch_size'] + (opt['channels'],)\n",
    "opt['in_shape'] = opt['patch_size'] + (1,)\n",
    "opt['rnd_crop'] = False\n",
    "opt['is_aug'] = True\n",
    "\n",
    "opt['model_restored'] = False\n",
    "opt['model_restored_epoch'] = 95 # from 35 add random combine   // from 44 to nrmse\n",
    "opt['model_total_epoch'] = 200\n",
    "opt['model_save_interval'] = 5\n",
    "\n",
    "opt['learning_rate'] = 2e-5\n",
    "opt['beta_1'] = 0.9\n",
    "opt['beta_2'] = 0.99\n",
    "\n",
    "opt['loss'] = nrmse\n",
    "opt['display_nums'] = [50,20,30]\n",
    "\n",
    "opt['model_save_path'] = '/home/sylar/data/results/model1_revision/pocsnet2_model'\n",
    "opt['checkpoint_path'] = opt['model_save_path']+\"/cp{epoch}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt['model_restored'] == False:\n",
    "    index = list(range(1,1001))\n",
    "    random.shuffle(index)\n",
    "    opt['train_index'] = index[0:950]\n",
    "    opt['val_index'] = index[950:1000]\n",
    "    np.save(opt['model_save_path'] + '/train_index8.npy', opt['train_index'])\n",
    "    np.save(opt['model_save_path'] + '/val_index2.npy', opt['val_index'])\n",
    "else:\n",
    "    opt['train_index'] = np.load(opt['model_save_path']+'/train_index8.npy')\n",
    "    opt['val_index'] = np.load(opt['model_save_path']+'/val_index2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt['train_data'] = Data_loaders_dpinv(opt)\n",
    "x1_train, x2_train, y_train = opt['train_data'].next([1],opt)\n",
    "print(opt['train_data'].data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loading data preshow'''\n",
    "ch,cw,cd = findcenter3d(y_train[0])\n",
    "aa=cw\n",
    "dd=cd\n",
    "\n",
    "f, axarr = plt.subplots(2, 3, figsize=(20, 10))\n",
    "axarr[1,0].imshow(np.flip(np.transpose(x1_train[0,:,aa,:].squeeze()),0))\n",
    "axarr[1,0].axis('off')\n",
    "axarr[0,2].imshow(np.transpose(y_train[0,:,:,dd].squeeze()))\n",
    "axarr[0,2].axis('off')\n",
    "axarr[0,0].imshow(np.transpose(x1_train[0,:,:,dd].squeeze()))\n",
    "axarr[0,0].axis('off')\n",
    "axarr[1,1].imshow(np.flip(np.transpose(x2_train[0,:,aa,:].squeeze()),0))\n",
    "axarr[1,1].axis('off')\n",
    "axarr[1,2].imshow(np.flip(np.transpose(y_train[0,:,aa,:].squeeze()),0))\n",
    "axarr[1,2].axis('off')\n",
    "axarr[0,1].imshow(np.transpose(x2_train[0,:,:,dd].squeeze()))\n",
    "axarr[0,1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "D = dipole_kernel(opt)\n",
    "model = {}\n",
    "\n",
    "model['vnet'] = unet_at2(opt, 1)\n",
    "x = Input(shape=opt['img_shape'])\n",
    "\n",
    "x_k = phase2qsm(x,D,opt)\n",
    "g = x_k\n",
    "\n",
    "for it in range(opt['iter']):\n",
    "    net_out = model['vnet'](x_k)\n",
    "\n",
    "    #updata x_k, qsm\n",
    "    x_k = g + opt['lbd2']*phaseinv(net_out,D,opt)\n",
    "\n",
    "model['optimizer'] = Adam(opt['learning_rate'], opt['beta_1'], opt['beta_2'])\n",
    "\n",
    "model['combine'] = Model(inputs = x,\n",
    "                     outputs = [net_out, x_k],\n",
    "#                      outputs = x_k,\n",
    "                     name='combine_model')\n",
    "\n",
    "model['combine'].compile(optimizer = model['optimizer'],\n",
    "                     loss = [opt['loss'],opt['loss']],\n",
    "                     loss_weights = [0.5, 0.5],\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "if opt['model_restored'] == True:\n",
    "    model['vnet'].load_weights(opt['checkpoint_path'].format(epoch = opt['model_restored_epoch']))\n",
    "    start_epoch = opt['model_restored_epoch']\n",
    "else:\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr_train_im = opt['train_data'].data_size\n",
    "nr_im_per_epoch = int(np.ceil(nr_train_im / opt['batch_size']) * opt['batch_size'])\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start Time:\" + str(start_time))\n",
    "\n",
    "avg_epoch_cost = []\n",
    "print('-----Start Training-----')\n",
    "for epoch in range(start_epoch, opt['model_total_epoch']):\n",
    " \n",
    "    order = np.concatenate((np.random.permutation(nr_train_im),\n",
    "                                         np.random.randint(nr_train_im, size=nr_im_per_epoch - nr_train_im)))\n",
    "    avg_img_cost = []\n",
    "    for block_i in range(1, nr_im_per_epoch+1, opt['batch_size']):\n",
    "        index = order[block_i:block_i+opt['batch_size']]\n",
    "        x1_train, x2_train, y_train = opt['train_data'].next(index, opt)\n",
    "\n",
    "        # Training\n",
    "        x_in = x2_train\n",
    "        Loss = model['combine'].train_on_batch(x = x_in, y = [y_train,y_train])\n",
    "        [y_pred1, y_pred2] = model['combine'].predict(x_in)\n",
    "        m_loss1 = Loss[0]\n",
    "        m_loss2 = 0\n",
    "        m_loss3 = 0\n",
    "        norm_loss = np.linalg.norm(y_pred1-y_train)/np.linalg.norm(y_train)\n",
    "        avg_img_cost.append(m_loss1)\n",
    "        if block_i % (30 * opt['batch_size'])==1:\n",
    "            # Plot the progress\n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [Model loss: %f-%f-%f ; nrmse: %f]\" % (epoch, opt['model_total_epoch'],\n",
    "                                                                block_i, nr_train_im,\n",
    "                                                                m_loss1,m_loss2,m_loss3, norm_loss))\n",
    "            display_slice(opt['display_nums'], y_pred1,y_pred1, y_train)\n",
    "    avg_epoch_cost.append(np.mean(avg_img_cost)) \n",
    "                                \n",
    "    print(\"Epoch:\", '%04d' % (epoch), \"Training_cost=\", \"{:.5f}\".format(avg_epoch_cost[-1]))\n",
    "    display_error(range(start_epoch,epoch+1),avg_epoch_cost)\n",
    "\n",
    "    # If at save interval => save models\n",
    "    if epoch % opt['model_save_interval'] == 0:\n",
    "        model['vnet'].save_weights(opt['checkpoint_path'].format(epoch=epoch))\n",
    "            \n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Total Time:\" + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
